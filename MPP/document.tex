\documentclass[10pt,a4paper,oneside,titlepage]{article}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{cmll}
\usepackage{enumerate}
\usepackage{stmaryrd}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm,bindingoffset=0cm]{geometry}
\usepackage{url}
\usepackage{listingsutf8}
\usepackage{graphicx}
\graphicspath{{pictures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\lstset{%
	numbers = left
}

\title{Конспект по курсу Паралелльное программирование \thanks{Читаемый Романом Елизаровым  Никитой Ковалем в 2018-2019 годах}}
\author{Александра Лисицына \thanks{Студентка группы М3334}}

\theoremstyle{plain}
\newtheorem{theorem}{Теорема}[section]
\newtheorem{lemma}{Лемма}[section]

\theoremstyle{defenition}
\newtheorem*{defenition}{Определение}

\begin{document}
	
\maketitle

\tableofcontents

\clearpage	
\section{Intoduction}
\subsection{Закон Мура}
Каждые 2 года количество транзисторов на процессоре удваивается.
До, примерно, 2005 года также росла частота ядра. Также начал замедляться рост производительность ядра. С 2005 года начался рост числа ядер.

\includegraphics*[scale=0.5]{Mura1}

\includegraphics*[scale=0.5]{Mura2}

\includegraphics*[scale=0.5]{Mura3}

\includegraphics*[scale=0.5]{Mura4}

\begin{defenition}
	{\bfseries Масштабирование} - свойство системы выполнять больше действий при увеличении мощности(традиционное), количества ядер(многопоточное).
\end{defenition}

В реале не получается сделать все идеально и для этого нужно изучать многопоточное программирование.

\subsection{Закон Амдала}
$$
S=\frac{Время на 1 ядре}{Время на N ядрах}
$$
где $S$ - это ускорение кода

Или
$$
S=\frac{1}{1-P+P/N}
$$
где $P$ - доля параллельного кода

Максимальное ускорение кода достигается при $N\to \infty$ и равно $1/(1-P)$

\begin{tabular}{cc}
	$P$&$S$\\[5pt]
	60\%&2.5\\
	95\%&20\\
	99\%&100\\
\end{tabular}

Поэтому нам необходимо увеличивать долю параллельного кода для достижения наилучшей масштабируемости.

\subsection{Разные виды параллелизма}
\subsubsection{Параллелизм на уровне инструкций (ILP)}\footnotetext{Instuction Level Parallelism}
Способы использования ILP

\begin{itemize}
	\item Конвейер
	
	\item Суперскалярное исполнение\footnote{Несколько операций за такт}
	
	\begin{itemize}
		\item Внеочередное исполнение
		
		\item Переименование регистров\footnote{Чтобы не возникало ложной зависимости по регистрам}
		
		\item Спекулятивное исполнение\footnote{Начинает выполнять одну из веток перехода, пытаясь ее предсказать}
		
		\item Предсказание переходов
	\end{itemize}

    \item Длинное машинное слово (VLIW\footnote{Very Long Instuction Word})
    
    \item Векторизация (SIMD)
\end{itemize}

\begin{figure}[h]
	\centering
	\includegraphics*[width=0.7\linewidth]{pictures/Processors}
	\caption{}
	\label{fig:processors}
\end{figure}

У параллелизма на уровне инструкций есть предел, поэтому нам необходимо параллельное программирование

\paragraph{Симметричная мультипроцессорность (SMP)}\footnotetext{Symmetric Multiprocessing}

Несколько вычислительных ядер у каждого свой поток исполняемых ресурсов

\begin{figure}[h]
	\centering
	\includegraphics*[width=0.4\linewidth]{pictures/SMP}
	\caption{SMP}
	\label{fig:smp}
\end{figure}



\paragraph{Одновременная многозадачность (SMT)}\footnotetext{Simultaneous Multithreading}

Два или более потока одновременно исполняются одним физическим ядром. Снаружи выглядит как SMP.

\begin{figure}[h]
	\centering
	\includegraphics*[width=0.4\linewidth]{pictures/SMT}
	\caption{SMT}
	\label{fig:smt}
\end{figure}



\paragraph{Ассимметричный доступ к памяти (NUMA)}\footnotetext{Non-uniform memory access}

Модель программирования та же, что в SMP, но без общей памяти.

\begin{figure}[h]
	\centering
	\includegraphics*[width=0.4\linewidth]{pictures/NUMA}
	\caption{NUMA}
	\label{fig:numa}
\end{figure}

\subsection{Операционные системы}
\begin{itemize}
	\item Типы
	\begin{itemize}
		\item Однозадачные
		\item Системы с пакетными задачами (batch processing)
		\item Многозадачные / с разделением времени (time sharing)
		\begin{itemize}
			\item Кооперативная многозадачность (cooperative multitasking)
			\item Вытесняющая многозадачность (preemptive multitasking)
		\end{itemize}
	\end{itemize}
    \item История многозадчности
    \begin{itemize}
    	\item Изначально нужно было для раздела одной дорогой машины между несколькими пользователями
    	\item Теперь нужно для использования ресурсов одной многоядерной машины для множества задач
    \end{itemize}
\end{itemize}

\subsection{Основные понятия в современных ОС}
\begin{itemize}
	\item \begin{defenition}
		{\bfseries Процесс} --- владеет памятью и ресурсами.
	\end{defenition}
	\item \begin{defenition}
		{\bfseries Поток} --- контекст исполнения внутри процесса.
	\end{defenition}
	\begin{itemize}
		\item В одном процессе может быть несколько потоков
		\item Все потоки работают с общей памятью процесса
	\end{itemize}
    \item Но в теории мы их будем смешивать
\end{itemize}

\subsection{Формализм}
\subsubsection{Модели программирования}
\begin{itemize}
	\item <<Классическое>> однопоточное / однозадачное
	\begin{itemize}
		\item Можем использовать ресурсы многоядерной системы только запустив несколько независимых задач
	\end{itemize}
    \item Многозадачное программирование
    \begin{itemize}
    	\item Возможность использовать ресурсы многоядерной системы в рамках решения одной задачи
    	\item Варианты:
    	\begin{itemize}
    		\item Модель с общей памятью
    		\item Модель с передачей сообщений (распределенное программирование)
    	\end{itemize}
    \end{itemize}
\end{itemize}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{pictures/CommonMemory}
	\caption{Модель с общими объектами (общей памятью)}
	\label{fig:commonmemory}
\end{figure}

\subsubsection{Общие объекты}
\begin{itemize}
	\item Потоки выполняют операции над общими, разделемыми объектами
	\item В этой моделе не важны операции внутри потоков
	\item Важна только коммуникация между потоками
	\item В этой моделе единственный тип коммуникации между потоками --- это работа с общими объектами
\end{itemize}

\subsubsection{Общие переменные}
\begin{itemize}
	\item Общие переменные --- это простейший тип общего объекта:
	\begin{itemize}
		\item У него есть значение определенного типа
		\item Есть операция чтения (read) и записи (write)
	\end{itemize}
    \item Общие переменные --- это базовые строительные блоки для многопоточных алгоритмов
    \item Модель с общими переменными --- это хорошая абстракция современных многопроцессорных систем и многопоточных ОС
    \begin{itemize}
    	\item На практике, это область памяти процесса, которая одновременно доступна для чтения и записи всем потокам этого процесса
    \end{itemize}
\end{itemize}

В теоретических трудах общие переменные называют регистрами

\subsubsection{Свойства многопоточных программ}
\begin{itemize}
	\item Последовательные программы детерминированы
	\begin{itemize}
		\item Если нет использования случайных чисел и другого явного общения с недетеминированным миром
		\item Их свойства можно установить анализируя последовательное исполнение при данных входных параметрах
	\end{itemize}
    \item Многопоточные программы в общем случае недетерминированы
    \begin{itemize}
    	\item Даже если код каждого потока детерминирован
    	\item Результат работы зависит от фактичекого исполнения при данных входных параметрах
    	\item А этих исполнений может быть много
    \end{itemize}
    \item Говорим <<Программа A имеет свойство P>> если она имеет это свойство при любом исполнении
\end{itemize}

\subsubsection{Моделирование многопотчного исполнения}

\begin{center}
	\begin{lstlisting}
	shared int x = 0, y = 0
	\end{lstlisting}
\end{center}
	
	\begin{minipage}{0.4\textwidth}
		Thread P:
		
		\begin{lstlisting}
		x = 1
		r1 = y
		stop
		\end{lstlisting}
	\end{minipage}
	\hfill
	\begin{minipage}{0.4\textwidth}
		Thread Q:
		
		\begin{lstlisting}
		y = 1
		r2 = x
		stop
		\end{lstlisting}
	\end{minipage}

\paragraph{Моделирование исполнений через чередование операций}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.3\linewidth]{pictures/Model}
	\caption{}
	\label{fig:model}
\end{figure}

\begin{itemize}
	\item $S$ --- это общее состояние:
	\begin{itemize}
		\item Состояние всех потоков (IP+locals)
		\item И состояние всех общих объектов
	\end{itemize}
    \item $f$ и $g$ --- это операции
    \begin{itemize}
    	\item Количество различных операций в каждом состоянии равно количеству потоков
    \end{itemize}
    \item $f(S)$ --- это новое состояние после применения операции $f$ к состоянию $S$ 
\end{itemize}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth]{pictures/Model1}
	\caption{}
	\label{fig:model1}
\end{figure}


После исполнеия этого кода для r1, r2 возможны следующие пары значений: (0, 0), (0, 1), (1, 0), (1, 1). Хотя при моделировании через чередование (рисунок~\ref{fig:model1}) первого варианта не получается. Это случается, так как в современном процессоре запись не попадает сразу в общую память, а в начале буферизируется (т.к. запись долгая операция). Поэтому мы можем прочитать старое значение, т.к. чтение быстрая операция и новые значения еще лежат в буфере. Процессор может переставить инструкции, т.к. это может ускорить однопоточный код (процессро не знает о параллельности).

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/Memory}
	\caption{}
	\label{fig:memory}
\end{figure}

Модель чередования не параллельна

На самом деле в настоящих процессорах операции чтения и записи не мгновенные. Они происходят паралелльно как в разных ядрах, так и в одном.

И вообще процессор обменивается с памятью сообщениями о чтении / записи и таких сообщений одновременно в обработке может быть очень много.

\section{Lock-free Treiber Stack and Michael-Scott Queue}

\section{Определения и формализм}
\subsection{Физическая реальность}
\begin{itemize}
	\item Свет (электромагнитные волны) в вакууме распространется со скоростью $\sim3\cdot10^8$ м/с.
	\begin{itemize}
		\item Это максимальный физический предел скорости
		\item За один такт процессора с частотой 3 ГГц ($3\cdot10^9$ Гц) свет в вакууме проходит всего 10 см.
	\end{itemize}
    \item Соседние процессоры физически не могут синхронизировать свою работу и физически не могут определить порядок происходящих в них событиях.
    \begin{itemize}
    	\item Они работают действительно физически параллельно
    \end{itemize}
    \item Пусть $a, b, c\in E$ --- это физически атомарные (неделимые) события, происходящие в пространстве--времени (рисунок~\ref{fig:model2})
    \begin{itemize}
    	\item Говорим <<$a$ предшествует $b$>> или <<$a$ произошло до $b$>> (и записываем $a\to b$), если свет от точки пространства--времени $a$ успевает дойти до точки пространства--времени $b$.
    	\item Это отношение частичного пордка на событиях
    \end{itemize}
\end{itemize}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth]{pictures/Model2}
	\caption{}
	\label{fig:model2}
\end{figure}

\subsection{Модель <<произошло до>> (happens before)}
\begin{itemize}
	\item Впервые введена Л.~Лампортом в 1978 году.
	\item Исполнение системы --- это пара ($H, \to_H$)
	\begin{itemize}
		\item $H$ --- это множество операций $e, f, g, \ldots$ (чтение и запись ячеек памяти и т.~п.) произошедших во время исполнения
		\item $\to_H$ --- это транзитивное, антирефлексивное, ассимметричное отношение (частичный строгий порядок) на множестве операций
		\item $e\to_Hf$ означает, что <<$e$ произошло до $f$ в исполнении $H$>>. Чаще всего исполнение $H$ понятно из контекста и опускается 
	\end{itemize}
    \item Две операции $e$ и $f$ параллельны ($e\parallel f$), если $e\nrightarrow f\wedge f\nrightarrow e$.
    \item Система --- это набор всех возможных исполнений системы
    \item Говорим, что <<система имеет свойство P>>, если каждое исполнение системы имеет свойство P.
\end{itemize}

\subsection{Модель глобального времени}

В этой моделе каждая операция --- это временный интервал (рисунок~\ref{fig:model3}) $e=[t_{inv}(e), t_{res}(e)]$ где $t_{inv}(e), t_{res}(e)\in\mathbb{R}$ и
$$
e\to f\stackrel{\mathrm{def}}{=}t_{res}(e)<t_{inv}(f)
$$

\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{pictures/Model3}
	\caption{Модель глобального времени}
	\label{fig:model3}
\end{figure}

\subsection{Обсуждение глобального времени}
На самом деле никакого глобального времени нет и не может быть из--за физических ограничений.

\begin{itemize}
	\item Это всего лишь механизм, позволяющий визуализировать факт существования параллельных операций.
	\item При доказательстве различных фактов и анализе свойств [исполнений] системы время не используется
	\begin{itemize}
		\item Анализируютя только операции и отношения <<произошло до>>
	\end{itemize}
\end{itemize}

\subsection{<<Произошло до>> на практике}
\begin{itemize}
	\item Современные языки программирования предоставляют программисту операции синхронизации:
	\begin{itemize}
		\item Специальные механизмы чтения и записи переменных
		\item Создание потоков и ожидание их завершения
		\item Различные другие библиотечные примитивы для синхронизации
	\end{itemize}
    \item Модель памяти языка программирования определяет то, каким образом исполнение операций синхронизации создает отношение <<произошло до>>
    \begin{itemize}
    	\item Без них разные потоки выполняются параллельно
    	\item Можно доказать те или иные свойства многопоточного кода, используя гарантии на возможные исполнения, которые дает модель памяти
    \end{itemize}
\end{itemize}

\subsection{Свойства исполнений над общими объектами}
\subsubsection{Операции над общими объектами}
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{pictures/Write}
	\caption{Запись}
	\label{fig:write}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{pictures/Read}
	\caption{Чтение}
	\label{fig:read}
\end{figure}


\subsubsection{Последовательное исполнение}
\begin{defenition}
	Исполнение системы называется последовательным, если все операции линейно--упорядочены отношением <<произошло до>>, то есть $\forall e, f\in H\colon (e=f)\vee(e\to f)\vee(f\to e)$.
\end{defenition}

\begin{figure}
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/Model4}
	\caption{Последовательное исполнение}
	\label{fig:model4}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/Model5}
	\caption{Параллельное исполнение}
	\label{fig:model5}
\end{figure}

\subsubsection{Конфликты и гонки данных (data race)}
\begin{itemize}
	\item \begin{defenition}
		Две операции над одной переменной, одна из которых запись, называются конфликтующими.
	\end{defenition}
    Конфликтующие операции не коммутируют в модели чередования.
	\item \begin{defenition}
		Если две конфликтующие операции произошли параллельно, то такая ситуация называется гонка данных (data race).
	\end{defenition} 
	\begin{itemize}
		\item Это свойство конкретного исполнения.
	\end{itemize}
\end{itemize}

\begin{defenition}
	Программа, в любом допустимом исполнении которой (с точки зрения модели памяти) нет гонок данных, называется корректно синхронизированной.
\end{defenition}

\subsubsection{Правильное исполнение} 
\begin{itemize}
	\item $H|_p$ --- сужение исполнения на поток $P$, то есть исполнение, где остались только операции, происходящие в потоке $P$.
	\item \begin{defenition}
		Исполнение называется {\bfseries правильным (well-formed)}, если его сужение на каждый поток $P$ является последовательным (рисунок~\ref{fig:model6}).
	\end{defenition} 
\end{itemize}
\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{pictures/Model6}
	\caption{Правильное исполнение}
	\label{fig:model6}
\end{figure}

\subsubsection{Правильное исполнение и нотация}
\begin{itemize}
	\item $H|_p$ --- сужение исполнения на поток $P$ --- это множестов всех операций $e\in H$, таких что $proc(e)=P$.
	\begin{itemize}
		\item Исполнение называется {\bfseries правильным (well-formed)}, если его сужение на каждый поток $P$ является последовательным.
		\item Задается программой, которую выполняет поток.
		\item \begin{defenition}
			Объединение всех сужений на потоки называют {\bfseries пргораммным порядком} (po = program order).
		\end{defenition}
	    \item Нас интерисуют только правильные исполнения.
	\end{itemize}
    \item $H|_x$ --- сужение истории на объект $x$ --- это множество операций $e\in H$, таких что $obj(e)=x$. В правильном исполнении сужение на объект е обязательно является последовательным.
\end{itemize}

\subsubsection{Последовательная спецификация объекта}
Если сужение исполнения на объект $H|_x$ является последовательным, то можно проверить его на соответсвие {\bfseries последовательной спецификации объекта}.

\subsubsection{Допустимое последовательное исполнение}
\begin{defenition}
	Последовательное исполнение является {\bfseries допустимым (legal)}, если выполнены последовательные спецификации всех объектов (рисунок~\ref{fig:model7}).
\end{defenition}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth]{pictures/Model7}
	\caption{Допустимое исполнение}
	\label{fig:model7}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth]{pictures/Model8}
	\caption{Недопустимое исполнение}
	\label{fig:model8}
\end{figure}

\subsubsection{Условия согласованности (корректности)}
{\bfseries Корректные} последовательные программы должны считаться {\bfseries согласованными}.

Условия согласованности:
\begin{itemize}
	\item Согласованность при покое
	\item Последовательная согласованность
	\item Лианеризуемость
	\item и другие
\end{itemize}

\paragraph{Последовательная согласованность}
\begin{defenition}
	Исполнение {\bfseries последовательно согласованно}, если ему можно сопоставить эквивалентное ему допустимое исполнение, сохраняющее его программный порядок (рисунок~\ref{fig:model9}).
\end{defenition}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth]{pictures/Model9}
	\caption{Последовательно согласованно}
	\label{fig:model9}
\end{figure}

Последовательная согласованность на каждом объекте исполнения не влечет последовательную согласованость всего исполнения (рисунок~\ref{fig:model10})

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{pictures/Model10}
	\caption{}
	\label{fig:model10}
\end{figure}

Модель памяти языков программрования и системы исполнения кода используют последовательную согласованность для своих формулировок.

\paragraph{Лианеризуемость}
\begin{defenition}
	Исполнение {\bfseries лианеризуемо}, если можно сопоставить эквивалентное ему допустимое последовательное исполнение, которое сохраняет отношение <<произошло до>>. 
\end{defenition}

Свойства лианеризуемости:
\begin{itemize}
	\item В лианеризуемом исполнении каждой операции $e$ можно сопоставить точку глобального времени ({\bfseries точку лианеризации}) $t(e)\in\mathbb{R}$ так, что время различных операций различно и
	$$
	e\to f\Rightarrow t(e)<t(f)
	$$
	\item Лианеризуемость {\bfseries локальна}. Лианеризуемость исполнения на каждом объекте эквивалентна лианеризуемости системы целиком.
	\item \begin{defenition}
		Операции над лианеризуемыми объектами называют {\bfseries атомарными}.
	\end{defenition}
\end{itemize}

\paragraph{Лианеризуемость в глобальном времени}

В глобальном времени исполнение лианеризуемо тогда и только тогда, когда точки лианеризуемости можно выбрать так, что
$$
\forall e\colon t_{inv}(e)<t(e)<t_{res}(e)
$$

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth]{pictures/Model11}
	\caption{Лианеризуемость}
	\label{fig:model11}
\end{figure}

\subsection{Лианеризуемость}
Исполнение системы, выполняющей операции над лианеризуемыми объектами, можно анализировать в модели чередования.

Из более простых лианеризуемых объектов можно сделать лианеризуемые объекты более высокого уровня. 

Когда говорят, что объект безопасен для использования из нескольких потоков, подразумевают, что операции над ним лианеризуемы.

\subsubsection{Применительо к Java}
\begin{itemize}
	\item Все операции над volatile полями в Java, согласно JMM, являются операциями синхронизации, которые всегда линейно--упорядочены в любом исполнении и соглосованы с точки зрения чтения/записи.
	\item Но операции над не volatile полями могут нарушать не только лианеризуемость, но даже последовательную согласованность, при отсутствии синхронизации.
	\item Если программа корректно синхронизированна, то JMM дает гарантию последовательно согласованного исполнения всего кода. 
\end{itemize}

\section{Построение атомарных объектов и блокировки}
\subsection{Сложные и составные операции}
\subsubsection{Формализация сложных операций}
\begin{itemize}
	\item Операция $e\in H$ может быть сложной. Даже чтение из памяти это продолжительное по времени действие, много шагов.
	\item {\bfseries Событие}
	\begin{itemize}
		\item Неделимое, простое физическое действие
		\item Множество событий обозначим $G$
		\item Каждая операция это множество событий $e\subset G$
	\end{itemize}
    \item Из всех событий выделяют два наиболее важных
    \begin{itemize}
    	\item Вызов операции $inv(e)\in G$
    	\item Завершение операции $res(e)\in G$
    \end{itemize}
    \item Декомпозиция исполнения --- ($H$, $G$, $\to_G$, inv, res)
    \begin{itemize}
    	\item $H$ --- это множество операций ($\forall e\in H\colon e\subset G$)
    	\item $G$ --- это множество событий
    	\item $\to_G$ --- отношение <<произошло до>> на событиях из $G$.
    	\item inv, res --- фукции из $H$ в $G$, такие что:
    	$$
    	\forall e\in H\colon inv(e)\to_Gres(e)
    	$$
    	$$
    	\forall e\in H, g\in e, g\ne inv(e), g\ne res(e)\colon inv(e)\to_Gg\to_Gres(e)
    	$$
    \end{itemize}
\end{itemize}

\section{Consensus}
\subsection{Задача о консенсусе}

Каждый поток использует объект Consensus один раз

\begin{itemize}
	\item Согласованность: все потоки должны вернуть одно и тоже значение из метода decide
	\item Обоснованность: возвращенное значение было входным значением какого-то из потоков
	\item Без ожидания
\end{itemize}

\subsection{Консенсусное число}
\begin{itemize}
	\item Если с помощью класса атомарных объектов C и атомарных регистров можно реализовать консенсусный протокол без ожидания с помощью детерминированного алгоритма для N потоков (и не больше), то говорят, что у класса C консенсусное число N.
	\item \begin{theorem}
		Атомарные регистры имеют консенсусное число 1.
	\end{theorem} 
\end{itemize}

\subsection{Модель}
\begin{itemize}
	\item x--валентное состояние системы --- консенсус во всех нижестоящих листьях будет x.
	\item Бивалентное состояние --- возможен консенсус как 0, так и 1.
	\item Критическое состояние --- такое бивалентное состояние, у которого все дети одновалентны
\end{itemize}

\subsection{Read--Modify--Write регистры}

\subsection{Универсальность консенсуса}
\begin{theorem}
	Любой последовательный объект можно реализовать без ожидания для N потоков, используя консенсусный проткол для N потоков
\end{theorem}

\section{Алгоритмы без блокировок: Построение на регистрах}
\subsection{Безусловные условия прогресса}
\begin{itemize}
	\item Отсутствие помех --- Если несколько потоков пытаются выполнить операцию, то любой из них должен выполнить ее за конечное время, если все другие остановить в любом месте
	\item Отсутствие блокировки --- если несколько потоков пытаются выполнить операцию, то хотя бы один из них должен выполнить ее за конечное время, независимо от действия или бездействия других потоков
	\item Отсутствие ожидания --- если поток хочет выполнить операцию, то он выполнит ее за конечное время независимо от других потоков
\end{itemize}

\section{Практические построения на списках}

\subsection{МНожество на односвязном списке}

\begin{lstlisting}
interface Set{
   fun add(key: Int)
   fun contains(key: Int): Boolean
   fun remove(key: Int)
}
\end{lstlisting}

Элементы упорядочены по возрастанию (рисунок~\ref{fig:set1}).

\begin{figure}
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/Set1}
	\caption{Односвязный список}
	\label{fig:set1}
\end{figure}

Пустой список состоит из двух граничных элементов (рисунок~\ref{fig:set2}).

\begin{figure}
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/Set2}
	\caption{Пустой список}
	\label{fig:set2}
\end{figure}

\subsubsection{Алгоритм}

\begin{itemize}
	\item Элементы упорядочены по возрастанию
	\item Ищем окно $(cur, next)$, что $cur.KEY<key\leqslant next.KEY$ и $cur.N=next$
	\item Искомый элемент будет в $next$
	\item Новый элемент добавляем между $cur$ и $next$
\end{itemize}

\subsubsection{Псевдокод}

\lstinputlisting{SetEasy.kt}

\subsubsection{Проблема}

При параллельном удалении соседних элементов могут возникнуть проблемы с перенаправление ссылок: например, мы успели удалить $cur$ перед тем как переназначить ссылки и у нас взникнет NullPointerException или список просто разорвется

\subsection{Грубая синхронизация}

\begin{itemize}
	\item Coarse-grained locking
	\item Используем общую блокировку для всех операций
	\item $\Rightarrow$ обеспечиваем последовательное исполнение
	\item В Java для этого можно использовать synchronized и java.utils.concurrent.locks.ReentrantLock
\end{itemize}

\subsection{Тонкая блокировка}

\begin{itemize}
	\item Fine-Grained locking
	\item Своя блокировка на каждый элемент
	\item При поиске окна держим блокировку на текущий и следующий элемент
\end{itemize}

\subsubsection{Корректность}

\begin{itemize}
	\item Поиск окна: запись и чтение $cur.N$ не может происходить параллельно
	\item Модификация: во время изменения окно защищено блокировкой $\Rightarrow$ атомарно
	\item $\forall k$: операции с ключем $k$ лианеризуемы $\Rightarrow$ всё исполнение лианеризуемо
	\item Операции с ключем $k$ упорядочены взятием блокировки
\end{itemize}

\subsection{Оптимистичная синхронизация}

\subsubsection{Алгоритм абстрактной операции}

\begin{enumerate}
	\item Найти окно $(cur, next)$ без синхронизации
	\item Взять блокировки на $cur$ и $next$
	\item Проверит инвариант $cur.N=next$
	\item Проверить, что $cur$ не удалён
	\item Выполнить операцию
	\item При любой ошибке начать занаво
\end{enumerate}

\subsubsection{Проверка, что узел не удалён}

\begin{itemize}
	\item Держи блокировку на $cur$ и $cur$ удалён $\Rightarrow$ не увидим при проходе
	\item Попробуем найти $cur$ ещё раз за $O(n)$ и проверим, что $cur.N=next$
\end{itemize}

\subsubsection{Валидация окна}

\begin{lstlisting}
fun validate(cur: Node, next: Node): Boolean {
    node := head
    while (node.key < cur.key) {
        node = node.N
    }    
    return (cur, next) = (node, node.N)
}
\end{lstlisting}

\subsubsection{Корректность}

\begin{itemize}
	\item Поиск: запись и чтение $cur.N$ связаны отношением <<произошло до>>
	\item Можем говорить о лианеризуемости операция над одинаковыми ключами
	\item Точка лианеризации - взятие блокировки над $cur$
\end{itemize}

\subsection{Ленивая синхронизация}

\subsubsection{Идея ленивого удаления}

\begin{itemize}
	\item Добавим в Node поле removed типа Boolean
	\item Удаление в две фазы
	      \begin{enumerate}
	      	\item $node.removed=true$ --- логическое удаление
	      	\item Физическое удаление из списка
	      \end{enumerate}
    \item Инвариант: все не удалённые вершины в списке
    \item $\Rightarrow$ теперь не над проходить по всему списку в validate()
\end{itemize}

\subsubsection{Псевдокод}

\begin{lstlisting}
fun validate(cur: Node, next: Node): Boolean {
    return !cur.removed && !next.removed && cur.N=next
}
\end{lstlisting}

\subsection{Неблокирующая синхронизация}

\subsubsection{Неблокирующий поиск}

\begin{itemize}
	\item На момент чтения поля $N$ видим состояние на момент записи $N$ или новее
	\item $\Rightarrow$ можем не брать блокиовку при поиске
\end{itemize}

\begin{lstlisting}
fun contains(key: Int): Boolean {
    (cur, next) := findWindow(key)
    return next.key = key
}
\end{lstlisting}

\subsubsection{Неблокирующая модификация}

\begin{itemize}
	\item Объединим N и removed в одну переменную, пару $(N, removed)$
	\item Будем менять $(N, removed)$ атомарно
	\item Каждая операция модификации будет выполняться одни успешным CAS-ом
	\item В Java для этого есть AtomicMarkableReference
\end{itemize}

\section{Lock-free хеш таблица с открытой адресацией}

\subsection{ConcurrentHashMap}

\begin{itemize}
	\item Работает за $O(1)$ в среднем
	\item Использует внутри блокировки $\Rightarrow$ не так хорошо масштабируется
	\item Хранит списки при коллизии (рисунок~\ref{fig:concurrenthashmap1})
	\begin{itemize}
		\item $\Rightarrow$ лишние cache miss-ы
		\item зато может хранить дерево при постоянных коллизиях (рисунок~\ref{fig:concurrenthashmap2})
	\end{itemize}
\end{itemize}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/ConcurrentHashMap1}
	\caption{Simple ConcureentHashMap}
	\label{fig:concurrenthashmap1}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/ConcurrentHashMap2}
	\caption{ConcurrentHashMap with tree}
	\label{fig:concurrenthashmap2}
\end{figure}

\subsection{Skip List}

\begin{itemize}
	\item Работает за $O(\log(n))$ в среднем
	\item <<Дерево>> списков
	\begin{itemize}
		\item Много лишних объектов
		\item $\Rightarrow$ постоянные cache miss-ы и нагружает GC 
	\end{itemize}
    \item И вообще это не хеш таблица
\end{itemize}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/SkipList}
	\caption{Skip List}
	\label{fig:skiplist}
\end{figure}

\subsection{Потенциальные проблемы}
\begin{itemize}
	\item ConcurrentHashMap
	\begin{itemize}
		\item Использует внутри блокировки $\Rightarrow$ не lock-free\footnote{Это важно для высоконагруженных систем}
		\item Использует списки $\Rightarrow$ cache miss-ы
	\end{itemize}
    \item Много <<лишних>> объектов
    \item Постоянные cache miss-ы
\end{itemize}

\subsection{NonBlockingHashMap}

\begin{itemize}
	\item Использует открытую адресацию
	\item Lock-free
	\begin{itemize}
		\item Гарантирует, что система не стоит на месте даже при неудачном scheduling-е
		\item Можно вставлять читать во время перехеширования
	\end{itemize}
\end{itemize}

\begin{lstlisting}
public T getInternal(long key) {
    int i = index(key);
    long k;
    int probes = 0;
    while ((k = keys.get(i)) != key) {
        if (k == NULL_KEY) 
            return null;
        if (++probes >= MAX_PROBES)
            return null;
        if (i == 0) 
           i = length;
        i--;
    }
    return values.get(i);
}
\end{lstlisting}

\subsubsection{Пара деталей}

\begin{itemize}
	\item Теория говорит, что размер таблицы должен быть простым числом, но так как операция взятия по модулю дорогая, то на практике используется степени двойки, для которых требуется только сдвиг
	\item В теории при поиске элемента лучше смотреть не на следующий элемент, но на практике наоборот, так как следующий уже скорее всего закэширован  
\end{itemize}

\subsection{MRSW хеш таблица (рисунок~\ref{fig:element1})}

Увеличение в случае одного писателя:
\begin{enumerate}
	\item Создаем новую таблицу
	\item Копируем элементы
	\item Меняем ссылку на таблицу
\end{enumerate}

\begin{figure}
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/Element1}
	\caption{Простая жизнь ячейки}
	\label{fig:element1}
\end{figure}

\subsection{MRMW хеш таблица}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/Element2}
	\caption{Жизнь ячейки без переноса}
	\label{fig:element2}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/Element3}
	\caption{Жизнь ячейки с переносом}
	\label{fig:element3}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.4\linewidth]{pictures/Element4}
	\caption{Другой взгляд на перенос}
	\label{fig:element4}
\end{figure}

\subsubsection{Кооперация при переносе}

\begin{itemize}
	\item Переносить блоками по k элементов
	\item Переносом занимается один выделенный поток
\end{itemize}

\section{CASN}
\subsection{Списки против массивов}
\begin{itemize}
	\item Список
	\begin{itemize}
		\item $3*N$ слов памяти (минимум)
		\item при многопотном использовании хватает одного CAS для добавления элемента
	\end{itemize}
    \item Массив
    \begin{itemize}
    	\item $5+N$ слов памяти (до $5+2*N$ при х2 резерве)
    	\item Как минимум в два раз быстрее работает с памятью (обычно растет на попрядок) (при однопоточной работе)
    	\item Для добавления нужно CAS2 (для size и элемента) --- эта операция не поддерживается на процессорах
    \end{itemize}
\end{itemize}



\subsection{CASn}

\begin{lstlisting}
class Ref<T>(intial: T) {
   var _v
   \\...
\end{lstlisting}

\subsubsection{DCSS}

\begin{lstlisting}
fun <A,B> dcss(
    a: Ref
\end{lstlisting}

\subsection{Наблюдения и замечания}

\subsection{Подход к реализации}

\section{Мониторы и ожидание}
\subsection{Объекты как функции}
\begin{itemize}
	\item Операция над объектом как функция
	\item Ранее опеарции были всюду определены на паре (S, P)
\end{itemize}

\subsection{Очередь ограниченного размера с ожиданием}

\subsection{Лианеризуемость операций с ожиданием}
\begin{itemize}
	\item Расширим понятие исполнения
	\begin{itemize}
		\item Есть событие вызова inv(A)
		\item Но не обязателен ответ resp(A)
		\begin{itemize}
			\item\begin{defenition}
				A это {\bfseries незавершенная} операция, если нет resp(A)
			\end{defenition}
		\end{itemize}
	\end{itemize}
\end{itemize}

\subsection{Реализация через монитор}
Monitor = mutex + conditional variables
\begin{itemize}
	
	\item
\end{itemize}

\subsection{Монитор в Java}
В Java каждый объект имеет монитор с одной условной переменной

В некотрых сстемах wait() реализован как хэш-таблица, при чем при коллизии кого-нибудь разбудим.

Wait() и notify() можно использовать только внутри критической секции (в synchronized)

Так как в мониторе только одна условная переменная, то, если у нас есть потоки ожидающие разных событий, то мы не можем использовать метод notify(), так как мы можем разбудить не тот поток.

\subsection{ReentrantLock}

\subsection{Подробней про interrupt}

\subsection{Ожидание без блокировки}

\section{Железо и спин-локи}
Так как у каждого ядра есть кэш, то он читает значение не и глобальной памяти, а из кэша, что ломает нам многопоточность. Решение - протокол MESI

\subsection{Backoff}
delay() - рандомизированный, т.к. если если несколько потоков ломанулись в блокировку и одному повезло, то он иожет очень быстро выполнить операцию и без делэя все остальные потоки снова ломанутся, это будет плохо, а если будет рандомищированный делэй, то кому-то из потоков повезет и он будет маленькое количество времени спать, и быстро схватит блокировку. Это очень важно, если у нас короткая блокировка.

Но этот алгоритм был нечестным, так как поток мог прийти последним и получить блокировку первым.

Напишем алгоритм с fist-come-first-served : CLH Lock

Isolation - пока транзакция работает, дригие не должны видеть несогласованный результат
Consistency - струдники не исчезают

\end{document}